{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKLekfqBrPBC8Jb70dVOzO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alihassan7212/IMU-Based-Security-layer/blob/main/IMU_Based_Additional_Security_Layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Description:**\n",
        "This code block performs the transformation of a CSV file, calculating the mean and variance for each numeric column and saving the results into a new CSV file. Here's a breakdown of the code:\n",
        "\n",
        "1. **Load CSV Data:**\n",
        "   - The code starts by loading a CSV file named '4th.csv' into a Pandas DataFrame.\n",
        "\n",
        "2. **Calculate Mean and Variance:**\n",
        "   - It then iterates through each column in the DataFrame, checking if the data type is numeric ('int64' or 'float64').\n",
        "   - For numeric columns, it calculates both the mean and variance.\n",
        "   - The results are stored in a new DataFrame named 'result', where each column is prefixed with 'mean_' or 'variance_'.\n",
        "\n",
        "3. **Save Results to CSV:**\n",
        "   - The 'result' DataFrame is saved into a new CSV file named 'output.csv'.\n",
        "   - The `index=False` argument ensures that the index column is not included in the output file.\n",
        "\n",
        "4. **Display Result DataFrame:**\n",
        "   - The 'result' DataFrame is printed to the console, showing the calculated mean and variance for each numeric column.\n",
        "\n",
        "**Note:**\n",
        "- Ensure to replace '4th.csv' with the actual path to your input CSV file.\n",
        "- The output file 'output.csv' will contain the mean and variance values for numeric columns.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "yIFk04XVjxbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "input_csv_path = '4th.csv'  # Replace with the actual path to your CSV file\n",
        "output_csv_path = 'output.csv'  # Replace with the desired path for the output CSV file\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv(input_csv_path)\n",
        "\n",
        "# List of column names\n",
        "columns = df.columns\n",
        "\n",
        "# Calculate mean and variance for each column\n",
        "result = pd.DataFrame()\n",
        "for col in columns:\n",
        "    # Skip non-numeric columns\n",
        "    if df[col].dtype in ['int64', 'float64']:\n",
        "        # Calculate mean and variance\n",
        "        mean_value = df[col].mean()\n",
        "        variance_value = df[col].var()\n",
        "\n",
        "        # Append to the result DataFrame\n",
        "        result[f'mean_{col}'] = [mean_value]\n",
        "        result[f'variance_{col}'] = [variance_value]\n",
        "\n",
        "# Save the result DataFrame to a new CSV file\n",
        "result.to_csv(output_csv_path, index=False)\n",
        "\n",
        "# Display the result DataFrame\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb5uv_2uRV6J",
        "outputId": "da4be291-6727-4214-a041-f210bbe2c217"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    mean_ax  variance_ax   mean_ay  variance_ay   mean_az  variance_az  \\\n",
            "0  0.111419     1.198795 -0.015748     0.974566  0.378903     7.529893   \n",
            "\n",
            "    mean_wx  variance_wx  mean_wy  variance_wy   mean_wz  variance_wz  \n",
            "0  0.037591     0.674414 -0.00921     0.901395  0.002077     0.405054  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description:**\n",
        "This code block processes a collection of CSV files within a specified folder, calculates the mean and variance for each numeric column in each file, and aggregates the results into a single output CSV file.\n",
        "\n",
        "1. **Set Input and Output Paths:**\n",
        "   - The `input_folder_path` variable is set to the path of the folder containing all input CSV files (e.g., '/content/Inputs').\n",
        "   - The `output_csv_path` variable is set to the desired path for the final output CSV file ('output.csv').\n",
        "\n",
        "2. **Initialize Result DataFrame:**\n",
        "   - An empty DataFrame named `all_results` is created to store the aggregated results.\n",
        "\n",
        "3. **Iterate Over CSV Files:**\n",
        "   - The code iterates over each file in the specified input folder.\n",
        "   - It checks if the file has a '.csv' extension.\n",
        "\n",
        "4. **Calculate Mean and Variance:**\n",
        "   - For each CSV file, the code reads the data into a Pandas DataFrame (`df`).\n",
        "   - It then calculates the mean and variance for each numeric column in the DataFrame.\n",
        "   - The results for each file are stored in a temporary DataFrame named `result`.\n",
        "\n",
        "5. **Aggregate Results:**\n",
        "   - The results from each file (`result`) are concatenated to the `all_results` DataFrame, ensuring a consistent index.\n",
        "\n",
        "6. **Save Aggregated Results to CSV:**\n",
        "   - The final aggregated results are saved to the output CSV file ('output.csv'), and the index column is excluded from the output.\n",
        "\n",
        "7. **Display the Final Results:**\n",
        "   - The final aggregated results DataFrame (`all_results`) is printed to the console.\n",
        "\n",
        "**Note:**\n",
        "- Make sure to replace '/content/Inputs' with the actual path to your input folder.\n",
        "- The output file 'output.csv' will contain the mean and variance values for numeric columns across all input CSV files.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "JD1kLv-zj738"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Set the path to the folder containing all sample files\n",
        "input_folder_path = '/content/Inputs'  # Replace with the actual path to your sample files\n",
        "\n",
        "# Set the path for the output CSV file\n",
        "output_csv_path = 'output.csv'  # Replace with the desired path for the output CSV file\n",
        "\n",
        "# Initialize an empty DataFrame to store the results\n",
        "all_results = pd.DataFrame()\n",
        "\n",
        "# Iterate over each file in the input folder\n",
        "for filename in os.listdir(input_folder_path):\n",
        "    if filename.endswith(\".csv\"):\n",
        "        # Construct the full path to the current sample file\n",
        "        input_csv_path = os.path.join(input_folder_path, filename)\n",
        "\n",
        "        # Read the current sample CSV file into a DataFrame\n",
        "        df = pd.read_csv(input_csv_path)\n",
        "\n",
        "        # Calculate mean and variance for each column\n",
        "        result = pd.DataFrame()\n",
        "        for col in df.columns:\n",
        "            # Skip non-numeric columns\n",
        "            if df[col].dtype in ['int64', 'float64']:\n",
        "                # Calculate mean and variance\n",
        "                mean_value = df[col].mean()\n",
        "                variance_value = df[col].var()\n",
        "\n",
        "                # Append to the result DataFrame\n",
        "                result[f'mean_{col}'] = [mean_value]\n",
        "                result[f'variance_{col}'] = [variance_value]\n",
        "\n",
        "        # Append the result to the overall results DataFrame\n",
        "        all_results = pd.concat([all_results, result], ignore_index=True)\n",
        "\n",
        "# Save the final results to the output CSV file\n",
        "all_results.to_csv(output_csv_path, index=False)\n",
        "\n",
        "# Display the final results DataFrame\n",
        "print(all_results)\n"
      ],
      "metadata": {
        "id": "wX6Ujgy7SWA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Description:**\n",
        "This code block demonstrates the training and evaluation of a logistic regression classifier using labeled data from an output CSV file.\n",
        "\n",
        "1. **Load Labeled Data:**\n",
        "   - The code sets the path to the labeled output CSV file ('output1.csv') and reads it into a Pandas DataFrame (`df`).\n",
        "\n",
        "2. **Separate Features and Labels:**\n",
        "   - The features are extracted from the DataFrame by excluding the last column (labels).\n",
        "   - The labels are extracted by selecting only the last column.\n",
        "\n",
        "3. **Split Data into Training and Testing Sets:**\n",
        "   - The labeled data is split into training and testing sets using the `train_test_split` function from scikit-learn.\n",
        "   - 80% of the data is used for training (`X_train`, `y_train`), and 20% is reserved for testing (`X_test`, `y_test`).\n",
        "\n",
        "4. **Initialize Logistic Regression Model:**\n",
        "   - A logistic regression model is initialized using `LogisticRegression()` from scikit-learn.\n",
        "\n",
        "5. **Train the Model:**\n",
        "   - The model is trained on the training set (`X_train`, `y_train`) using the `fit` method.\n",
        "\n",
        "6. **Make Predictions:**\n",
        "   - The trained model is used to make predictions on the test set (`X_test`), generating predictions (`y_pred`).\n",
        "\n",
        "7. **Evaluate Model Performance:**\n",
        "   - The code calculates various metrics to evaluate the performance of the classifier.\n",
        "   - Accuracy, confusion matrix, and a classification report are printed to the console.\n",
        "\n",
        "8. **Display Results:**\n",
        "   - The accuracy, confusion matrix, and classification report are printed to the console for result analysis.\n",
        "\n",
        "**Note:**\n",
        "- Make sure to replace 'output1.csv' with the actual path to your labeled output CSV file.\n",
        "- The code assumes a binary classification task, where the last column of the CSV file contains the labels (1 or 0).\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "pFlbHghXkRM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Set the path to your labeled output CSV file\n",
        "labeled_output_csv_path = 'output1.csv'  # Replace with the actual path to your labeled output CSV file\n",
        "\n",
        "# Read the labeled output CSV file into a DataFrame\n",
        "df = pd.read_csv(labeled_output_csv_path)\n",
        "\n",
        "# Separate features (mean and variance columns) and labels\n",
        "features = df.iloc[:, :-1]  # Exclude the last column (labels)\n",
        "labels = df.iloc[:, -1]  # Select only the last column (labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=19)\n",
        "\n",
        "# Initialize a Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Display the results\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Classification Report:\\n{classification_rep}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBFK0d0hZbjp",
        "outputId": "4ffd9387-50f0-4238-eac8-14fdc5c30453"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Confusion Matrix:\n",
            "[[1 0]\n",
            " [0 1]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_pred = model.predict(np.array([[0.11141868, 1.19879488, -0.01574751, 0.97456641, 0.3789027, 7.52989342, 0.03759055, 0.67441371, -0.00920987, 0.90139453, 0.00207742, 0.40505368\n",
        "]]))\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehuoIeK2cQMH",
        "outputId": "6dc3ff7b-ab9a-4af0-93bb-0008adbf2d2f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description:**\n",
        "\n",
        "This code block demonstrates how to use a trained logistic regression model to make predictions on a given array of numerical values. Here's a breakdown of the code:\n",
        "\n",
        "1. **Assume Trained Model:**\n",
        "   - The code assumes that there's a pre-trained logistic regression model named 'model.' Ensure that the model is trained and loaded before running this code.\n",
        "\n",
        "2. **Given Comma-Separated Array:**\n",
        "   - A sample numeric array named 'given_array' is provided. This array represents a set of features for which predictions will be made.\n",
        "\n",
        "3. **Convert to NumPy Array:**\n",
        "   - The given array is converted into a NumPy array named 'given_array_np' to match the format expected by the model.\n",
        "\n",
        "4. **Make Predictions:**\n",
        "   - The trained logistic regression model is used to make predictions on the given array using the `predict` method.\n",
        "\n",
        "5. **Display Prediction Result:**\n",
        "   - The code checks the predicted label (1 or 0) and prints the corresponding class result.\n",
        "     - If the prediction is 1, it prints \"Class A.\"\n",
        "     - If the prediction is 0, it prints \"Class O.\"\n",
        "\n",
        "**Note:**\n",
        "- Ensure that the 'model' variable is correctly assigned to your trained logistic regression model.\n",
        "- Modify the 'given_array' with your own set of numeric values for prediction.\n",
        "\n",
        "This code snippet is useful for making predictions on new data using a trained model, allowing you to classify the given array into one of the predefined classes (Class A or Class O)."
      ],
      "metadata": {
        "id": "tnvwoBTvkdDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assume 'model' is your trained logistic regression model\n",
        "\n",
        "# Given comma-separated array\n",
        "given_array = [0.208672087, 1.410032988, -0.03103794, 0.623948529, 0.341056911, 1.700471802, -0.002677507, 0.751336499, 0.010674797, 2.757705074, -0.036685637, 0.36597657]\n",
        "\n",
        "# Convert the list to a NumPy array\n",
        "given_array_np = np.array([given_array])\n",
        "\n",
        "# Make predictions using the trained model\n",
        "prediction = model.predict(given_array_np)\n",
        "\n",
        "# Display the prediction\n",
        "if prediction[0] == 1:\n",
        "    print(\"Class A\")\n",
        "else:\n",
        "    print(\"Class O\")\n"
      ],
      "metadata": {
        "id": "lXHjSkBcdBhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def process_temporal_data_and_predict(csv_path, trained_model):\n",
        "    # Read the temporal CSV file into a DataFrame\n",
        "    df_temporal = pd.read_csv(csv_path)\n",
        "\n",
        "    # Calculate mean and variance for each column\n",
        "    result = pd.DataFrame()\n",
        "    for col in df_temporal.columns:\n",
        "        if df_temporal[col].dtype in ['int64', 'float64']:\n",
        "            mean_value = df_temporal[col].mean()\n",
        "            variance_value = df_temporal[col].var()\n",
        "            result[f'mean_{col}'] = [mean_value]\n",
        "            result[f'variance_{col}'] = [variance_value]\n",
        "\n",
        "    # Make predictions using the trained model\n",
        "    prediction = trained_model.predict(result)\n",
        "\n",
        "    # Display the prediction\n",
        "    if prediction[0] == 1:\n",
        "        return \"Class A\"\n",
        "    else:\n",
        "        return \"Class O\"\n",
        "\n",
        "# Replace 'path/to/your/temporal_data.csv' with the actual path to your temporal CSV file\n",
        "temporal_csv_path = '6tho.csv'\n",
        "prediction_result = process_temporal_data_and_predict(temporal_csv_path, model)\n",
        "\n",
        "print(\"Prediction Result:\", prediction_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LdTBc-ng-Li",
        "outputId": "fed06ad4-8fce-45d0-dc6d-f7271b99bef9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction Result: Class O\n"
          ]
        }
      ]
    }
  ]
}